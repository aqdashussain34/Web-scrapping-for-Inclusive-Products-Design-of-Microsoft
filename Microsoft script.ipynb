{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d610300-35c3-4d8e-bbb2-6dcd0df1cda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Website scraped successfully.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Save as (1) Formatted DOCX or (2) PDF:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Microsoft.docx\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Would you like to generate a summary? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      " Download Inclusive Design for Mental Health cards (PDF)\n",
      "Case Studies: Creating for Cognition\n",
      "Browse our curated selection of stories about how employees and customers reduced cognitive exclusion in their products. Download inclusive activity cards (PDF)\n",
      "Inclusive Design in action\n",
      "At Microsoft, our technology is intended to deliver increased access, reduced friction, and more emotional context to the greatest number of people. Inclusive Design is for you\n",
      "Whether you're a program manager, engineer, data scientist, designer, or anyone else who helps create products and services, Inclusive Design is a practice you can follow. Microsoft Inclusive Design\n",
      "Skip to main content\n",
      "Microsoft Inclusive Design\n",
      "Inclusive Design is a methodology, born out of digital environments, that enables and draws on the full range of human diversity. Download Case Studies: Creating for Cognition (PDF)\n",
      "Inclusive Design for Cognition Screeners\n",
      "These screeners are questions for recruiting co-creators that align with each cognitive area and many situational contexts.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from docx import Document\n",
    "from fpdf import FPDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Ensure required NLTK resources are available\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Function to scrape website data\n",
    "def scrape_website(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        return soup.get_text(separator='\\n')\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to save scraped data in a well-formatted DOCX file\n",
    "def save_to_docx(scraped_data, filename='Microsoft.docx'):\n",
    "    document = Document()\n",
    "    lines = scraped_data.split(\"\\n\")\n",
    "    document.add_heading('Scraped Web Content', level=1)\n",
    "\n",
    "    for line in lines:\n",
    "        if \"Inclusive Design\" in line:\n",
    "            document.add_heading(line, level=2)\n",
    "        elif line.strip():\n",
    "            document.add_paragraph(line)\n",
    "    \n",
    "    document.save(filename)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "# Function to save scraped data in PDF format\n",
    "def save_to_pdf(scraped_data, filename='Microdoft.pdf'):\n",
    "    pdf = FPDF()\n",
    "    pdf.set_auto_page_break(auto=True, margin=15)\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "    for line in scraped_data.split(\"\\n\"):\n",
    "        pdf.multi_cell(0, 10, line)\n",
    "    \n",
    "    pdf.output(filename)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "# Function to preprocess text for summarization\n",
    "def preprocess_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    processed_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence.lower())\n",
    "        words_filtered = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "        processed_sentences.append(\" \".join(words_filtered))\n",
    "    \n",
    "    return sentences, processed_sentences\n",
    "\n",
    "# Function to perform extractive summarization using TF-IDF\n",
    "def extractive_summary(text, num_sentences=5):\n",
    "    original_sentences, processed_sentences = preprocess_text(text)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(processed_sentences)\n",
    "\n",
    "    sentence_scores = tfidf_matrix.sum(axis=1)\n",
    "    ranked_sentences = [(score, sent) for score, sent in zip(sentence_scores, original_sentences)]\n",
    "    ranked_sentences.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "    summary = \" \".join([sent for _, sent in ranked_sentences[:num_sentences]])\n",
    "    return summary\n",
    "\n",
    "# Main function to scrape, save, and summarize data\n",
    "def main():\n",
    "    url = \"https://inclusive.microsoft.design/\"\n",
    "    scraped_data = scrape_website(url)\n",
    "\n",
    "    if scraped_data:\n",
    "        print(\"Website scraped successfully.\")\n",
    "\n",
    "        format_choice = input(\"Save as (1) Formatted DOCX or (2) PDF: \")\n",
    "        if format_choice == '1':\n",
    "            save_to_docx(scraped_data)\n",
    "        elif format_choice == '2':\n",
    "            save_to_pdf(scraped_data)\n",
    "        else:\n",
    "            print(\"Invalid choice! Please choose either 1 or 2.\")\n",
    "        \n",
    "        summary_choice = input(\"Would you like to generate a summary? (y/n): \")\n",
    "        if summary_choice.lower() == 'y':\n",
    "            summary = extractive_summary(scraped_data, num_sentences=5)\n",
    "            print(\"\\nSummary:\\n\", summary)\n",
    "        else:\n",
    "            print(\"Summary generation skipped.\")\n",
    "    else:\n",
    "        print(\"Failed to scrape the website.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87da142-ad54-4ba6-b8a5-9bdb62eb0807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
